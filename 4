#!/usr/bin/env python3

import cv2
import math
import numpy as np
import time

import dlib
assert dlib.DLIB_USE_CUDA
assert dlib.cuda.get_num_devices() > 0

import pathlib
DLIB_LANDMARK_PREDICTOR_PATH = "dlib_shape_predictor.dat"
if not pathlib.Path(DLIB_LANDMARK_PREDICTOR_PATH).exists():
    import urllib.request
    urllib.request.urlretrieve("http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2", DLIB_LANDMARK_PREDICTOR_PATH + ".bz2")
    import bz2
    zipfile = bz2.BZ2File(DLIB_LANDMARK_PREDICTOR_PATH + ".bz2")
    decompressed = zipfile.read()
    open(DLIB_LANDMARK_PREDICTOR_PATH, 'wb').write(decompressed)

DLIB_FACE_DETECTOR = dlib.get_frontal_face_detector()
DLIB_LANDMARK_PREDICTOR = dlib.shape_predictor(DLIB_LANDMARK_PREDICTOR_PATH)

SCALE_UP_BEFORE_DETECTING_FACES = 0
LOG_DISPLAY_UPSCALE = 2

FACE_BBOX = None
FACE_BBOX_LAST_UPDATE = None
FACE_BBOX_UPDATE_PERIOD_SECONDS = 0.5

DISPLAY_FACE_BBOX = True
DISPLAY_ALL_FACE_POINTS = False
DISPLAY_RELEVANT_FACE_LINES = True

NOSE_TOP = None
NOSE_BASE = None

GRAPH_SIZE_CHARS = 100

DECAY_EXTREMES=0.999
BROW_L_MIN = None
BROW_L_MAX = None
BROW_R_MIN = None
BROW_R_MAX = None
MOUTH_MIN = None
MOUTH_MAX = None

def show(im):
    cv2.imshow('Livestream', im)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        exit(0)

def point2np(point):
    return np.array([point.x, point.y])

def proj_onto_axis(a, b):
    return a.dot(b) / b.dot(b)

def clamp_to_unit(x):
    if x < 0.:
        return 0.
    if x > 1.:
        return 1.
    return x

GRAPH_TEXT_LENGTH = None
def graph(name, value):
    global GRAPH_TEXT_LENGTH
    strlen = len(name)
    if GRAPH_TEXT_LENGTH is None or strlen > GRAPH_TEXT_LENGTH:
        GRAPH_TEXT_LENGTH = strlen
    else:
        for _ in range(strlen, GRAPH_TEXT_LENGTH):
            name = " " + name

    graph = ""
    quantized = int(GRAPH_SIZE_CHARS * clamp_to_unit(value)
    for _ in range(0, quantized)):
        graph = graph + "%"
    for _ in range(quantized, GRAPH_SIZE_CHARS)):
        graph = graph + " "
    print(f"{name}: [{graph}] ({value})")

def process(bgr):
    global DLIB_FACE_DETECTOR
    global DLIB_LANDMARK_PREDICTOR
    global FACE_BBOX
    global FACE_BBOX_LAST_UPDATE
    global NOSE_TOP
    global NOSE_BASE
    global BROW_L_MIN
    global BROW_L_MAX
    global BROW_R_MIN
    global BROW_R_MAX
    global MOUTH_MIN
    global MOUTH_MAX

    height, width, channels = bgr.shape

    # Convert to grayscale:
    im = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)

    update_face_bbox = (FACE_BBOX_LAST_UPDATE is None)
    if not update_face_bbox:
        face_bbox_staleness = (time.time() - FACE_BBOX_LAST_UPDATE) / FACE_BBOX_UPDATE_PERIOD_SECONDS
        if face_bbox_staleness >= 1.:
            update_face_bbox = True

    if update_face_bbox:
        face_bbox_updated = False
        face_bboxes = DLIB_FACE_DETECTOR(im, SCALE_UP_BEFORE_DETECTING_FACES)
        for i, bbox in enumerate(face_bboxes):
            face_bbox_updated = True
            FACE_BBOX = bbox

        if FACE_BBOX is None:
            print("Waiting to detect a face...")
            return

        if face_bbox_updated:
            if FACE_BBOX_LAST_UPDATE is None or face_bbox_staleness > 2.:
                FACE_BBOX_LAST_UPDATE = time.time()
                face_bbox_staleness = 0.
            else:
                FACE_BBOX_LAST_UPDATE = FACE_BBOX_LAST_UPDATE + FACE_BBOX_UPDATE_PERIOD_SECONDS
                face_bbox_staleness = face_bbox_staleness - 1.

    landmarks = DLIB_LANDMARK_PREDICTOR(im, FACE_BBOX)

    multiplier = 1
    for _ in range(0, LOG_DISPLAY_UPSCALE):
        bgr = cv2.pyrUp(bgr)
        multiplier = 2 * multiplier

    if DISPLAY_FACE_BBOX:
        x, y = FACE_BBOX.left() * multiplier, FACE_BBOX.top() * multiplier
        w = (FACE_BBOX.right() * multiplier) - x
        if face_bbox_staleness > 1.:
            face_bbox_staleness = 1.
        color = (0, int(255. * (1. - face_bbox_staleness)), int(255. * face_bbox_staleness))
        cv2.rectangle(bgr, (x, y), (FACE_BBOX.right() * multiplier, FACE_BBOX.bottom() * multiplier), color, (w + 511) // 512)
        cv2.putText(bgr, "Face", (x, y - ((w + 127) // 128)), cv2.FONT_HERSHEY_SIMPLEX, w / 512., color, (w + 511) // 512)

    if DISPLAY_ALL_FACE_POINTS:
        for i, point in enumerate(landmarks.parts()):
            x = point.x * multiplier
            y = point.y * multiplier
            m = (multiplier + 1) // 2 # `+ 1` just so this is not 0 when m = 1
            cv2.circle(bgr, (x, y), m, (255, 0, 0), -1)
            cv2.putText(bgr, f"{i}", (x, y - m), cv2.FONT_HERSHEY_SIMPLEX, w / 1024., (0, 255, 0), (w + 1023) // 1024)

    brow_left_right = point2np(landmarks.part(20))
    brow_right_left = point2np(landmarks.part(23))
    lip_lower_center = point2np(landmarks.part(66))
    lip_upper_center = point2np(landmarks.part(62))
    nose_top = point2np(landmarks.part(27))
    nose_base = point2np(landmarks.part(33))

    NOSE_TOP = nose_top if NOSE_TOP is None else (0.9 * NOSE_TOP + 0.1 * nose_top)
    NOSE_BASE = nose_base if NOSE_BASE is None else (0.9 * NOSE_BASE + 0.1 * nose_base)
    nose_axis = NOSE_TOP - NOSE_BASE

    standardized_face_size = np.linalg.norm(nose_axis)
    brow_l = proj_onto_axis(brow_left_right - NOSE_TOP, nose_axis)
    brow_r = proj_onto_axis(brow_right_left - NOSE_TOP, nose_axis)
    mouth_open = proj_onto_axis(lip_upper_center - lip_lower_center, nose_axis)

    BROW_L_MIN = brow_l if BROW_L_MIN is None or brow_l < BROW_L_MIN else DECAY_EXTREMES * BROW_L_MIN
    BROW_L_MAX = brow_l if BROW_L_MAX is None or brow_l < BROW_L_MAX else DECAY_EXTREMES * BROW_L_MAX
    BROW_R_MIN = brow_r if BROW_R_MIN is None or brow_r < BROW_R_MIN else DECAY_EXTREMES * BROW_R_MIN
    BROW_R_MAX = brow_r if BROW_R_MAX is None or brow_r < BROW_R_MAX else DECAY_EXTREMES * BROW_R_MAX
    MOUTH_MIN = mouth if MOUTH_MIN is None or mouth < MOUTH_MIN else DECAY_EXTREMES * MOUTH_MIN
    MOUTH_MAX = mouth if MOUTH_MAX is None or mouth < MOUTH_MAX else DECAY_EXTREMES * MOUTH_MAX

    brow_l = clamp_to_unit()

    print()
    print(f"Standardized face size: {standardized_face_size}")
    graph("Brow raise (L)", brow_l)
    graph("Brow raise (R)", brow_r)
    graph("Mouth open", mouth_open)

    if DISPLAY_RELEVANT_FACE_LINES:

        brow_left_farleft = point2np(landmarks.part(17))
        brow_left_left = point2np(landmarks.part(18))
        brow_left_center = point2np(landmarks.part(19))
        brow_left_farright = point2np(landmarks.part(21))

        brow_right_farleft = point2np(landmarks.part(22))
        brow_right_center = point2np(landmarks.part(24))
        brow_right_right = point2np(landmarks.part(25))
        brow_right_farright = point2np(landmarks.part(26))

        lip_lower_left = point2np(landmarks.part(67))
        lip_lower_right = point2np(landmarks.part(65))

        mouth_corner_left = point2np(landmarks.part(60))
        mouth_corner_right = point2np(landmarks.part(64))

        lip_upper_left = point2np(landmarks.part(61))
        lip_upper_right = point2np(landmarks.part(63))

        nose_tip = point2np(landmarks.part(30))

        cv2.line(bgr, (brow_left_farleft[0] * multiplier, brow_left_farleft[1] * multiplier), (brow_left_left[0] * multiplier, brow_left_left[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (brow_left_left[0] * multiplier, brow_left_left[1] * multiplier), (brow_left_center[0] * multiplier, brow_left_center[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (brow_left_center[0] * multiplier, brow_left_center[1] * multiplier), (brow_left_right[0] * multiplier, brow_left_right[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (brow_left_right[0] * multiplier, brow_left_right[1] * multiplier), (brow_left_farright[0] * multiplier, brow_left_farright[1] * multiplier), (255, 0, 0), (w + 511) // 512)

        cv2.line(bgr, (brow_right_farleft[0] * multiplier, brow_right_farleft[1] * multiplier), (brow_right_left[0] * multiplier, brow_right_left[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (brow_right_left[0] * multiplier, brow_right_left[1] * multiplier), (brow_right_center[0] * multiplier, brow_right_center[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (brow_right_center[0] * multiplier, brow_right_center[1] * multiplier), (brow_right_right[0] * multiplier, brow_right_right[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (brow_right_right[0] * multiplier, brow_right_right[1] * multiplier), (brow_right_farright[0] * multiplier, brow_right_farright[1] * multiplier), (255, 0, 0), (w + 511) // 512)

        cv2.line(bgr, (mouth_corner_left[0] * multiplier, mouth_corner_left[1] * multiplier), (lip_lower_left[0] * multiplier, lip_lower_left[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (lip_lower_left[0] * multiplier, lip_lower_left[1] * multiplier), (lip_lower_center[0] * multiplier, lip_lower_center[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (lip_lower_center[0] * multiplier, lip_lower_center[1] * multiplier), (lip_lower_right[0] * multiplier, lip_lower_right[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (lip_lower_right[0] * multiplier, lip_lower_right[1] * multiplier), (mouth_corner_right[0] * multiplier, mouth_corner_right[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (mouth_corner_right[0] * multiplier, mouth_corner_right[1] * multiplier), (lip_upper_right[0] * multiplier, lip_upper_right[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (lip_upper_right[0] * multiplier, lip_upper_right[1] * multiplier), (lip_upper_center[0] * multiplier, lip_upper_center[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (lip_upper_center[0] * multiplier, lip_upper_center[1] * multiplier), (lip_upper_left[0] * multiplier, lip_upper_left[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (lip_upper_left[0] * multiplier, lip_upper_left[1] * multiplier), (mouth_corner_left[0] * multiplier, mouth_corner_left[1] * multiplier), (255, 0, 0), (w + 511) // 512)

        # cv2.line(bgr, (nose_top[0] * multiplier, nose_top[1] * multiplier), (nose_tip[0] * multiplier, nose_tip[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        # cv2.line(bgr, (nose_tip[0] * multiplier, nose_tip[1] * multiplier), (nose_base[0] * multiplier, nose_base[1] * multiplier), (255, 0, 0), (w + 511) // 512)

        cv2.line(bgr, (int(NOSE_TOP[0]) * multiplier, int(NOSE_TOP[1]) * multiplier), (nose_tip[0] * multiplier, nose_tip[1] * multiplier), (255, 0, 0), (w + 511) // 512)
        cv2.line(bgr, (nose_tip[0] * multiplier, nose_tip[1] * multiplier), (int(NOSE_BASE[0]) * multiplier, int(NOSE_BASE[1]) * multiplier), (255, 0, 0), (w + 511) // 512)

    show(bgr)
